{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between two methods should be small: 6.050396565706963e-09\n",
      "Difference between two methods should be small: 6.369535889123952e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57786/2166954373.py:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  grad_flat[i] = (fn(Xp) - fn(Xn)) / (2 * eps)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def check_grad(fn, gr, X):\n",
    "    X_flat = X.reshape(-1) # chuyển ma trận X về mảng 1 chiều\n",
    "    shape_X = X.shape # lưu lại shape của X\n",
    "    num_grad = np.zeros_like(X) # tạo ma trận numerical grad có shape giống X\n",
    "    grad_flat = np.zeros_like(X_flat) # tạo mảng 1 chiều grad_flat có shape giống X_flat\n",
    "    eps = 1e-6 # giá trị epsilon\n",
    "    numElems = X_flat.shape[0] # số phần tử của X_flat\n",
    "    # tính toán numerical gradient\n",
    "    for i in range(numElems): # duyệt qua tất cả phần tử của X\n",
    "        Xp_flat = X_flat.copy() \n",
    "        Xn_flat = X_flat.copy()\n",
    "        Xp_flat[i] += eps\n",
    "        Xn_flat[i] -= eps\n",
    "        Xp = Xp_flat.reshape(shape_X)\n",
    "        Xn = Xn_flat.reshape(shape_X)\n",
    "        grad_flat[i] = (fn(Xp) - fn(Xn)) / (2 * eps)\n",
    "    num_grad = grad_flat.reshape(shape_X)\n",
    "    diff = np.linalg.norm(num_grad-gr(X)) # tính toán độ lệch giữa numerical gradient và gradient thực\n",
    "    print('Difference between two methods should be small:', diff)\n",
    "\n",
    "# Hàm số cần tính gradient: grad(trace(A*X)) == A^T\n",
    "\n",
    "m, n = 10, 20\n",
    "A = np.random.randn(m, n)\n",
    "X = np.random.randn(n, m)\n",
    "\n",
    "def fn1(X):\n",
    "    return np.trace(A.dot(X))\n",
    "\n",
    "def gr1(X):\n",
    "    return A.T\n",
    "\n",
    "check_grad(fn1, gr1, X)\n",
    "\n",
    "# Hàm số cần tính gradient: grad(x^T*A*x) == (A + A^T)*x\n",
    "\n",
    "A = np.random.randn(m, m)\n",
    "x = np.random.rand(m, 1)\n",
    "\n",
    "def fn2(x):\n",
    "    return x.T.dot(A).dot(x)\n",
    "\n",
    "def gr2(x):\n",
    "    return (A + A.T).dot(x)\n",
    "\n",
    "check_grad(fn2, gr2, x)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
